{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9aHTrpANhSoC"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAnqNAzfcVu0"
      },
      "source": [
        "# GoEmotions using PRADO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grmac7ZYj02a"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqP5qpAR1W4f"
      },
      "source": [
        "The seq_flow_lite library has been written with the assumption that tensorflow 2.10.0 will be used.  It may be necessary to restart the runtime after installing the correct version of Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hzuq_GVn1nXO"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXaKS_JBbyX1"
      },
      "source": [
        "Update CuDNN.  The version installed on the Colab machines does not play well with Tensorflow 2.10.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ErZoDw_9bwSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e22760-554e-4f2b-df0c-0a2eb8bac6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_mi4NZeeB1l"
      },
      "source": [
        "### Install the TensorFlow Datasets pip package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCk46-HdmIyD"
      },
      "source": [
        "`tensorflow_datasets` is a set of collection of datasets that includes the GoEmotions dataset. We install it with pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mvO0_HcKx0_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3a894d-2c66-4cf0-9101-0d79f17482a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.8/dist-packages (4.6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.9.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (3.19.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.3.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (4.64.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.11.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (5.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.21.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tensorflow_datasets) (3.10.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tensorflow_datasets) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.57.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2wqyg-7mbfV"
      },
      "source": [
        "### Install the Sequence Projection Models package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JRZS_aSeINK"
      },
      "source": [
        "Install Bazel: This will allow us to build custom TensorFlow ops used by the PRADO architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N00X4P229Ppm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7716a498-6e2d-4d90-cead-1666af4b35e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.58.0-2ubuntu3.21).\n",
            "gnupg is already the newest version (2.2.4-1ubuntu1.6).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4714  100  4714    0     0  14504      0 --:--:-- --:--:-- --:--:-- 14504\n",
            "OK\n",
            "deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\n",
            "Hit:1 https://storage.googleapis.com/bazel-apt stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 261 kB in 2s (151 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "bazel is already the newest version (5.3.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install curl gnupg\n",
        "!curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -\n",
        "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
        "!sudo apt update\n",
        "!sudo apt install bazel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JeSDpZFelL5"
      },
      "source": [
        "Install the library:\n",
        "* `seq_flow_lite` includes the PRADO architecture and custom ops.\n",
        "* We download the code from GitHub, and then build and install the TF and TFLite ops used by the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mktlCYcd9iLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7238a8d-57bf-4fef-a655-71148fbed37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "mv: cannot stat 'setup.py': No such file or directory\n",
            "touch: cannot touch '../../tf_ops/__init__.py': No such file or directory\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./models/research/seq_flow_lite\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "\u001b[33mWARNING: Discarding file:///content/models/research/seq_flow_lite. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://www.github.com/tensorflow/models\n",
        "!models/research/seq_flow_lite/demo/colab/setup_workspace.sh\n",
        "!pip install models/research/seq_flow_lite\n",
        "!rm -rf models/research/seq_flow_lite/tf_ops\n",
        "!rm -rf models/research/seq_flow_lite/tflite_ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP8iKa4Il4mL"
      },
      "source": [
        "## Training an Emotion Prediction Model\n",
        "\n",
        "* First, we load the GoEmotions data from TFDS.\n",
        "* Next, we prepare the PRADO model for training. We set up the model configuration, including hyperparameters and labels. We also prepare the dataset, which involves projecting the inputs from the dataset, and passing the projections to the model.  This is needed because a model training on TPU can not handle string inputs.\n",
        "* Finally, we train and evaluate the model and produce model-level and per-label metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ImEejssVKvxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e6f22d-2a33-4493-ec14-3fbeb693124d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/seq_flow_lite\n"
          ]
        }
      ],
      "source": [
        "%cd models/research/seq_flow_lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwSPqHXAeQ6H"
      },
      "source": [
        "* Import the Tensorflow and Tensorflow Dataset libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kc4y4n80eL_b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvsn_s3S0SAt"
      },
      "source": [
        "Load the data from TFDS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KtTLwtEqwcR2"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('goemotions', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to subset the dataset to single label entries only\n",
        "def remove_multilabels(ds):\n",
        "    df = tfds.as_dataframe(ds)\n",
        "    # df = df.drop('grief', axis=1) # drop grief column \n",
        "    col_names = [c for c in df.columns if c!=\"comment_text\" ]\n",
        "    df['sum'] = df[col_names].sum(axis=1)\n",
        "    df = df[df['sum']==1]\n",
        "    df = df.drop('sum', axis=1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(dict(df))\n",
        "    print()\n",
        "    return ds\n",
        "    # return df\n",
        "\n",
        "#subset data to single label entries only\n",
        "# ds_train = remove_multilabels(ds, 'train')\n",
        "# ds_valid = remove_multilabels(ds, 'validation')\n",
        "# ds_test = remove_multilabels(ds, 'test')\n"
      ],
      "metadata": {
        "id": "nb9riFxtx8IA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating TF tensors\n",
        "# train_tensor = tf.data.Dataset.from_tensor_slices((train, y_train)).shuffle(len(train)).batch(batchsize)\n",
        "# val_tensor = tf.data.Dataset.from_tensor_slices((val, y_valid)).shuffle(len(val)).batch(batchsize)\n",
        "# test_tensor = tf.data.Dataset.from_tensor_slices((test, y_test)).shuffle(len(test)).batch(batchsize)\n"
      ],
      "metadata": {
        "id": "HGp_hQqq0R2B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6rdEKjg0LUw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJuu4jKet9zq"
      },
      "source": [
        "Print 5 sample data elements from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y0O18rSLuDx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2a649e-19c8-486e-dd3d-154b4319239f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b\"It's just wholesome content, from questionable sources\">, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'This is actually awesome.'>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b\"People really spend more than $10 in an app game? I mean an actual video game I can understand but that's just...sad\">, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'I grew up on the other side of Ama but live in Tulia now. I will have some El Burrito for you'>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n",
            "{'admiration': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'amusement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'anger': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'annoyance': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'approval': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'caring': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'comment_text': <tf.Tensor: shape=(), dtype=string, numpy=b'What the problem? I mean, steak? Good. Doughnuts? Good!! I don\\xe2\\x80\\x99t see an issue. '>, 'confusion': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'curiosity': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'desire': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disappointment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'disapproval': <tf.Tensor: shape=(), dtype=bool, numpy=True>, 'disgust': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'embarrassment': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'excitement': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'fear': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'gratitude': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'grief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'joy': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'love': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'nervousness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'neutral': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'optimism': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'pride': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'realization': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'relief': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'remorse': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'sadness': <tf.Tensor: shape=(), dtype=bool, numpy=False>, 'surprise': <tf.Tensor: shape=(), dtype=bool, numpy=False>}\n"
          ]
        }
      ],
      "source": [
        "for element in ds.take(5):\n",
        "  print(element)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAz-tdQfuVBn"
      },
      "source": [
        "### The model: PRADO\n",
        "\n",
        "Prepare GoEmotions and PRADO for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9uPSZYpgBqP"
      },
      "source": [
        "Prepare the model configuration:\n",
        "* Enumerate the labels expected to be found in the GoEmotions dataset.\n",
        "* Prepare the `MODEL_CONFIG` dictionary which includes training parameters for the model. See sample configs for the PRADO model [here](https://github.com/tensorflow/models/tree/master/research/seq_flow_lite/configs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DkQMnTcLyFeR"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral',\n",
        "]\n",
        "\n",
        "# Model training parameters.\n",
        "CONFIG = {\n",
        "    'name': 'models.prado',\n",
        "    'batch_size': 1024,\n",
        "    'train_steps': 50000,\n",
        "    'learning_rate': 0.0006,\n",
        "    'learning_rate_decay_steps': 340,\n",
        "    'learning_rate_decay_rate': 0.7,\n",
        "}\n",
        "\n",
        "# BERT CONFIG for comparison\n",
        "CONFIG2 = {\n",
        "    'name': 'models.prado',\n",
        "    'batch_size': 32,\n",
        "    # 'train_steps': 10000,\n",
        "    'learning_rate': 0.00005,\n",
        "    # 'learning_rate_decay_steps': 340,\n",
        "    # 'learning_rate_decay_rate': 0.7,\n",
        "}\n",
        "\n",
        "\n",
        "# Limits the amount of logging output produced by the training run, in order to\n",
        "# avoid browser slowdowns.\n",
        "CONFIG['save_checkpoints_steps'] = int(CONFIG['train_steps'] / 25)\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    'labels': LABELS,\n",
        "    'multilabel': True,  \n",
        "    'quantize': False,\n",
        "    'max_seq_len': 128,  \n",
        "    'max_seq_len_inference': 128,\n",
        "    'exclude_nonalphaspace_unicodes': False,\n",
        "    'split_on_space': True,\n",
        "    'embedding_regularizer_scale': 0.035,\n",
        "    'embedding_size': 64,\n",
        "    'bigram_channels': 64,\n",
        "    'trigram_channels': 64,\n",
        "    'feature_size': 512,\n",
        "    'network_regularizer_scale': 0.0001,\n",
        "    'keep_prob': 0.5,\n",
        "    'word_novelty_bits': 0,\n",
        "    'doc_size_levels': 0,\n",
        "    'add_bos_tag': False,\n",
        "    'add_eos_tag': False,\n",
        "    'pre_logits_fc_layers': [],\n",
        "    'text_distortion_probability': 0.0,\n",
        "}\n",
        "\n",
        "CONFIG['model_config'] = MODEL_CONFIG"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Model Preprocessing Function"
      ],
      "metadata": {
        "id": "4mvsgXbB2mBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SUBSET\n",
        "# Building a preprocessing function to clean text\n",
        "def preprocess_corpus(x):\n",
        "\n",
        "  # Adding a space between words and punctation\n",
        "  x = re.sub( r'([a-zA-Z\\[\\]])([,;.!?])', r'\\1 \\2', x)\n",
        "  x = re.sub( r'([,;.!?])([a-zA-Z\\[\\]])', r'\\1 \\2', x)\n",
        "  \n",
        "  # Demojize\n",
        "  x = emoji.demojize(x)\n",
        "  \n",
        "  # Expand contraction\n",
        "  x = contractions.fix(x)\n",
        "  \n",
        "  # Lower\n",
        "  x = x.lower()\n",
        "\n",
        "  # #correct some acronyms/typos/abbreviations  \n",
        "  # x = re.sub(r\"lmao\", \"laughing my ass off\", x)  \n",
        "  # x = re.sub(r\"amirite\", \"am i right\", x)\n",
        "  # x = re.sub(r\"\\b(tho)\\b\", \"though\", x)\n",
        "  # x = re.sub(r\"\\b(ikr)\\b\", \"i know right\", x)\n",
        "  # x = re.sub(r\"\\b(ya|u)\\b\", \"you\", x)\n",
        "  # x = re.sub(r\"\\b(eu)\\b\", \"europe\", x)\n",
        "  # x = re.sub(r\"\\b(da)\\b\", \"the\", x)\n",
        "  # x = re.sub(r\"\\b(dat)\\b\", \"that\", x)\n",
        "  # x = re.sub(r\"\\b(dats)\\b\", \"that is\", x)\n",
        "  # x = re.sub(r\"\\b(cuz)\\b\", \"because\", x)\n",
        "  # x = re.sub(r\"\\b(fkn)\\b\", \"fucking\", x)\n",
        "  # x = re.sub(r\"\\b(tbh)\\b\", \"to be honest\", x)\n",
        "  # x = re.sub(r\"\\b(tbf)\\b\", \"to be fair\", x)\n",
        "  # x = re.sub(r\"faux pas\", \"mistake\", x)\n",
        "  # x = re.sub(r\"\\b(btw)\\b\", \"by the way\", x)\n",
        "  # x = re.sub(r\"\\b(bs)\\b\", \"bullshit\", x)\n",
        "  # x = re.sub(r\"\\b(kinda)\\b\", \"kind of\", x)\n",
        "  # x = re.sub(r\"\\b(bruh)\\b\", \"bro\", x)\n",
        "  # x = re.sub(r\"\\b(w/e)\\b\", \"whatever\", x)\n",
        "  # x = re.sub(r\"\\b(w/)\\b\", \"with\", x)\n",
        "  # x = re.sub(r\"\\b(w/o)\\b\", \"without\", x)\n",
        "  # x = re.sub(r\"\\b(doj)\\b\", \"department of justice\", x)\n",
        "  \n",
        "  # #replace some words with multiple occurences of a letter, example \"coooool\" turns into --> cool\n",
        "  # x = re.sub(r\"\\b(j+e{2,}z+e*)\\b\", \"jeez\", x)\n",
        "  # x = re.sub(r\"\\b(co+l+)\\b\", \"cool\", x)\n",
        "  # x = re.sub(r\"\\b(g+o+a+l+)\\b\", \"goal\", x)\n",
        "  # x = re.sub(r\"\\b(s+h+i+t+)\\b\", \"shit\", x)\n",
        "  # x = re.sub(r\"\\b(o+m+g+)\\b\", \"omg\", x)\n",
        "  # x = re.sub(r\"\\b(w+t+f+)\\b\", \"wtf\", x)\n",
        "  # x = re.sub(r\"\\b(w+h+a+t+)\\b\", \"what\", x)\n",
        "  # x = re.sub(r\"\\b(y+e+y+|y+a+y+|y+e+a+h+)\\b\", \"yeah\", x)\n",
        "  # x = re.sub(r\"\\b(w+o+w+)\\b\", \"wow\", x)\n",
        "  # x = re.sub(r\"\\b(w+h+y+)\\b\", \"why\", x)\n",
        "  # x = re.sub(r\"\\b(s+o+)\\b\", \"so\", x)\n",
        "  # x = re.sub(r\"\\b(f)\\b\", \"fuck\", x)\n",
        "  # x = re.sub(r\"\\b(w+h+o+p+s+)\\b\", \"whoops\", x)\n",
        "  # x = re.sub(r\"\\b(ofc)\\b\", \"of course\", x)\n",
        "  # x = re.sub(r\"\\b(the us)\\b\", \"usa\", x)\n",
        "  # x = re.sub(r\"\\b(gf)\\b\", \"girlfriend\", x)\n",
        "  # x = re.sub(r\"\\b(hr)\\b\", \"human ressources\", x)\n",
        "  # x = re.sub(r\"\\b(mh)\\b\", \"mental health\", x)\n",
        "  # x = re.sub(r\"\\b(idk)\\b\", \"i do not know\", x)\n",
        "  # x = re.sub(r\"\\b(gotcha)\\b\", \"i got you\", x)\n",
        "  # x = re.sub(r\"\\b(y+e+p+)\\b\", \"yes\", x)\n",
        "  # x = re.sub(r\"\\b(a*ha+h[ha]*|a*ha +h[ha]*)\\b\", \"haha\", x)\n",
        "  # x = re.sub(r\"\\b(o?l+o+l+[ol]*)\\b\", \"lol\", x)\n",
        "  # x = re.sub(r\"\\b(o*ho+h[ho]*|o*ho +h[ho]*)\\b\", \"ohoh\", x)\n",
        "  # x = re.sub(r\"\\b(o+h+)\\b\", \"oh\", x)\n",
        "  # x = re.sub(r\"\\b(a+h+)\\b\", \"ah\", x)\n",
        "  # x = re.sub(r\"\\b(u+h+)\\b\", \"uh\", x)\n",
        "\n",
        "  # # Handling emojis\n",
        "  x = re.sub(r\"<3\", \" love_heart \", x)\n",
        "  x = re.sub(r\"xd\", \" smiling_face_with_open_mouth_and_tightly_closed_eyes \", x)\n",
        "  x = re.sub(r\":\\)\", \" smiling_face \", x)\n",
        "  x = re.sub(r\"^_^\", \" smiling_face \", x)\n",
        "  x = re.sub(r\"\\*_\\*\", \" star_struck \", x)\n",
        "  x = re.sub(r\":\\(\", \" frowning_face \", x)\n",
        "  x = re.sub(r\":\\^\\(\", \" frowning_face \", x)\n",
        "  x = re.sub(r\";\\(\", \" frowning_face \", x)\n",
        "  x = re.sub(r\":\\/\",  \" confused_face\", x)\n",
        "  x = re.sub(r\";\\)\",  \" wink\", x)\n",
        "  x = re.sub(r\">__<\",  \" unamused \", x)\n",
        "  x = re.sub(r\"\\b([xo]+x*)\\b\", \" xoxo \", x)\n",
        "  x = re.sub(r\"\\b(n+a+h+)\\b\", \"nah\", x)\n",
        "\n",
        "  # # Handling special cases of text\n",
        "  # x = re.sub(r\"h a m b e r d e r s\", \"hamberders\", x)\n",
        "  # x = re.sub(r\"b e n\", \"ben\", x)\n",
        "  # x = re.sub(r\"s a t i r e\", \"satire\", x)\n",
        "  # x = re.sub(r\"y i k e s\", \"yikes\", x)\n",
        "  # x = re.sub(r\"s p o i l e r\", \"spoiler\", x)\n",
        "  # x = re.sub(r\"thankyou\", \"thank you\", x)\n",
        "  # x = re.sub(r\"a^r^o^o^o^o^o^o^o^n^d\", \"around\", x)\n",
        "\n",
        "  # Remove special characters and numbers replace by space + remove double space\n",
        "  x = re.sub(r\"\\b([.]{3,})\",\" dots \", x)\n",
        "  x = re.sub(r\"[^A-Za-z!?_]+\",\" \", x)\n",
        "  x = re.sub(r\"\\b([s])\\b *\",\"\", x)\n",
        "  x = re.sub(r\" +\",\" \", x)\n",
        "  x = x.strip()\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "e5tbYkg92pow"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-pUW649gfzA"
      },
      "source": [
        "Write a function that builds the datasets for the model.  It will load the data, handle batching, and generate projections for the input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "unYlUYXq119f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78b34dd-c329-4a7a-cabc-4485aecc802d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from layers import base_layers\n",
        "from layers import projection_layers\n",
        "\n",
        "def build_dataset(mode, inspect=False):\n",
        "  if mode == base_layers.TRAIN:\n",
        "    split = 'train'\n",
        "    count = None\n",
        "  elif mode == base_layers.EVAL:\n",
        "    split = 'test'\n",
        "    count = 1\n",
        "  else:\n",
        "    raise ValueError('mode={}, must be TRAIN or EVAL'.format(mode))\n",
        "\n",
        "  batch_size = CONFIG['batch_size']\n",
        "  if inspect:\n",
        "    batch_size = 1\n",
        "\n",
        "  # Convert examples from their dataset format into the model format.\n",
        "  def process_input(features):\n",
        "    # Generate the projection for each comment_text input.  The final tensor \n",
        "    # will have the shape [batch_size, number of tokens, feature size].\n",
        "    # Additionally, we generate a tensor containing the number of tokens for\n",
        "    # each comment_text (seq_length).  This is needed because the projection\n",
        "    # tensor is a full tensor, and we are not using EOS tokens.\n",
        "    text = features['comment_text']\n",
        "    text = tf.reshape(text, [batch_size])\n",
        "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
        "    projection, seq_length = projection_layer(text)\n",
        "\n",
        "    # Convert the labels into an indicator tensor, using the LABELS indices.\n",
        "    label = tf.stack([features[label] for label in LABELS], axis=-1)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    label = tf.reshape(label, [batch_size, len(LABELS)])\n",
        "\n",
        "    model_features = ({'projection': projection, 'sequence_length': seq_length}, label)\n",
        "\n",
        "    if inspect:\n",
        "      model_features = (model_features[0], model_features[1], features)\n",
        "\n",
        "    return model_features\n",
        "\n",
        "  ds = tfds.load('goemotions', split=split)\n",
        "  ds = remove_multilabels(ds)\n",
        "  ds = ds.repeat(count=count)\n",
        "  ds = ds.shuffle(buffer_size=batch_size * 2)\n",
        "  ds = ds.batch(batch_size, drop_remainder=True)\n",
        "  ds = ds.map(process_input,\n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "              deterministic=False)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_dataset = build_dataset(base_layers.TRAIN)\n",
        "test_dataset = build_dataset(base_layers.EVAL)\n",
        "inspect_dataset = build_dataset(base_layers.TRAIN, inspect=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.take(1)"
      ],
      "metadata": {
        "id": "IEPeAqg_1V8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b928c41-eddf-4481-cfbc-e7add37e00e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=({'projection': TensorSpec(shape=(1024, 128, 512), dtype=tf.float32, name=None), 'sequence_length': TensorSpec(shape=(1024,), dtype=tf.float32, name=None)}, TensorSpec(shape=(1024, 28), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQmYWg6ivCHS"
      },
      "source": [
        "Print a batch of examples in model format.  This will consist of:\n",
        "* the projection tensors (projection and seq_length)\n",
        "* the label tensor (second tuple value)\n",
        "\n",
        "The projection tensor is a **[batch size, max_seq_length, feature_size]** floating point tensor.  The **[b, i]** vector is a feature vector of the **i**th token of the **b**th comment_text.  The rest of the tensor is zero-padded, and the\n",
        "seq_length tensor indicates the number of features vectors for each comment_text.\n",
        "\n",
        "The label tensor is an indicator tensor of the set of true labels for the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1OyK7rjTvBjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bc1b69-a49c-4f69-8bf3-109c1be2dd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs = {'projection': <tf.Tensor: shape=(1024, 128, 512), dtype=float32, numpy=\n",
            "array([[[ 1.,  0.,  1., ...,  1., -1.,  0.],\n",
            "        [-1.,  1.,  0., ...,  1., -1.,  1.],\n",
            "        [ 0., -1.,  0., ...,  0., -1.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       [[-1.,  0.,  1., ..., -1., -1., -1.],\n",
            "        [-1., -1., -1., ..., -1.,  1.,  0.],\n",
            "        [ 0.,  0.,  1., ...,  0.,  0., -1.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       [[ 1.,  1.,  0., ...,  0.,  0.,  1.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0., -1.],\n",
            "        [ 1., -1.,  0., ...,  0.,  1.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.,  1., -1., ...,  1.,  1.,  0.],\n",
            "        [ 1., -1., -1., ...,  1.,  1., -1.],\n",
            "        [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       [[ 0., -1.,  1., ...,  0., -1., -1.],\n",
            "        [ 0.,  0.,  1., ...,  0., -1.,  0.],\n",
            "        [ 1., -1.,  0., ...,  1.,  0.,  1.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       [[ 0.,  0., -1., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0., -1., ...,  1.,  0.,  0.],\n",
            "        [ 0.,  0., -1., ..., -1.,  1.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)>, 'sequence_length': <tf.Tensor: shape=(1024,), dtype=float32, numpy=array([16., 23.,  9., ...,  6., 29., 11.], dtype=float32)>}\n",
            "labels = [[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "example = next(iter(train_dataset))\n",
        "print(\"inputs = {}\".format(example[0]))\n",
        "print(\"labels = {}\".format(example[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytMQHT5Kd7A_"
      },
      "source": [
        "In this version of the dataset, the original example has been added as the third element of the tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "29EzRoCfI91r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4de266-9fe6-42c1-cc6b-7e22b35100fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs = {'projection': <tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
            "array([[[ 1., -1.,  1., ...,  1.,  0., -1.],\n",
            "        [ 0.,  1., -1., ..., -1., -1.,  0.],\n",
            "        [-1.,  1.,  0., ..., -1., -1.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)>, 'sequence_length': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>}\n",
            "labels = [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n",
            "original example = {'admiration': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>, 'amusement': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'anger': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'annoyance': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'approval': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'caring': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'comment_text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'This is actually awesome.'], dtype=object)>, 'confusion': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'curiosity': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'desire': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'disappointment': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'disapproval': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'disgust': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'embarrassment': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'excitement': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'fear': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'gratitude': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'grief': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'joy': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'love': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'nervousness': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'neutral': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'optimism': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'pride': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'realization': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'relief': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'remorse': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'sadness': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>, 'surprise': <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>}\n"
          ]
        }
      ],
      "source": [
        "example = next(iter(inspect_dataset))\n",
        "print(\"inputs = {}\".format(example[0]))\n",
        "print(\"labels = {}\".format(example[1]))\n",
        "print(\"original example = {}\".format(example[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLDbHTIvvX11"
      },
      "source": [
        "### Train and Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqUTa7wXsHoO"
      },
      "source": [
        "First we define a function to build the model.  We vary the model inputs depending on task.  For training and evaluation, we'll take the projection and sequence length as inputs.  Otherwise, we'll take strings as inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "erEiNX3ToLZ1"
      },
      "outputs": [],
      "source": [
        "from models import prado\n",
        "\n",
        "def build_model(mode):\n",
        "  # First we define our inputs.\n",
        "  inputs = []\n",
        "  if mode == base_layers.TRAIN or mode == base_layers.EVAL:\n",
        "    # For TRAIN and EVAL, we'll be getting dataset examples,\n",
        "    # so we'll get projections and sequence_lengths.\n",
        "    projection = tf.keras.Input(\n",
        "        shape=(MODEL_CONFIG['max_seq_len'], MODEL_CONFIG['feature_size']),\n",
        "        name='projection',\n",
        "        dtype='float32')\n",
        "\n",
        "    sequence_length = tf.keras.Input(\n",
        "        shape=(), name='sequence_length', dtype='float32')\n",
        "    inputs = [projection, sequence_length]\n",
        "  else:\n",
        "    # Otherwise, we get string inputs which we need to project.\n",
        "    input = tf.keras.Input(shape=(), name='input', dtype='string')\n",
        "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
        "    projection, sequence_length = projection_layer(input)\n",
        "    inputs = [input]\n",
        "\n",
        "  # Next we add the model layer.\n",
        "  model_layer = prado.Encoder(MODEL_CONFIG, mode)\n",
        "  logits = model_layer(projection, sequence_length)\n",
        "\n",
        "  # Finally we add an activation layer.\n",
        "  if MODEL_CONFIG['multilabel']:\n",
        "    activation = tf.keras.layers.Activation('sigmoid', name='predictions')\n",
        "  else:\n",
        "    activation = tf.keras.layers.Activation('softmax', name='predictions')\n",
        "  predictions = activation(logits)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs=[predictions])\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caHpK9Htv40g"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2xM-2R38kogo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01695a3-5217-4960-b1b4-f5fa20a6e1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2000/2000 [==============================] - 164s 80ms/step - loss: 0.5479 - val_loss: 0.4694\n",
            "Epoch 2/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4501 - val_loss: 0.4434\n",
            "Epoch 3/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4397 - val_loss: 0.4390\n",
            "Epoch 4/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4385 - val_loss: 0.4413\n",
            "Epoch 5/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4423\n",
            "Epoch 6/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4416\n",
            "Epoch 7/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4404\n",
            "Epoch 8/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4381 - val_loss: 0.4409\n",
            "Epoch 9/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4395\n",
            "Epoch 10/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4419\n",
            "Epoch 11/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4383 - val_loss: 0.4409\n",
            "Epoch 12/25\n",
            "2000/2000 [==============================] - 160s 80ms/step - loss: 0.4383 - val_loss: 0.4413\n",
            "Epoch 13/25\n",
            "2000/2000 [==============================] - 160s 80ms/step - loss: 0.4382 - val_loss: 0.4393\n",
            "Epoch 14/25\n",
            "2000/2000 [==============================] - 160s 80ms/step - loss: 0.4382 - val_loss: 0.4407\n",
            "Epoch 15/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4383 - val_loss: 0.4409\n",
            "Epoch 16/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4382 - val_loss: 0.4409\n",
            "Epoch 17/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4419\n",
            "Epoch 18/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4418\n",
            "Epoch 19/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4381 - val_loss: 0.4408\n",
            "Epoch 20/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4382 - val_loss: 0.4415\n",
            "Epoch 21/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4383 - val_loss: 0.4425\n",
            "Epoch 22/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4383 - val_loss: 0.4411\n",
            "Epoch 23/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4383 - val_loss: 0.4409\n",
            "Epoch 24/25\n",
            "2000/2000 [==============================] - 159s 80ms/step - loss: 0.4382 - val_loss: 0.4391\n",
            "Epoch 25/25\n",
            "2000/2000 [==============================] - 159s 79ms/step - loss: 0.4381 - val_loss: 0.4414\n"
          ]
        }
      ],
      "source": [
        "# Remove any previous training data.\n",
        "!rm -rf model\n",
        "\n",
        "model = build_model(base_layers.TRAIN)\n",
        "\n",
        "# Create the optimizer.\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=CONFIG['learning_rate'],\n",
        "    decay_rate=CONFIG['learning_rate_decay_rate'],\n",
        "    decay_steps=CONFIG['learning_rate_decay_steps'],\n",
        "    staircase=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Define the loss function.\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "epochs = int(CONFIG['train_steps'] / CONFIG['save_checkpoints_steps'])\n",
        "model.fit(\n",
        "    x=train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_dataset,\n",
        "    steps_per_epoch=CONFIG['save_checkpoints_steps'])\n",
        "\n",
        "model.save_weights('model/model_checkpoint')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hdbXBs0g3oX"
      },
      "source": [
        "Load a training checkpoint and evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "A1qc9GNtF3s5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491c9579-2ef1-404f-f2ab-f3a44ec55b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 4s 74ms/step - loss: 0.0000e+00 - precision@0.5/admiration: 0.5000 - recall@0.5/admiration: 0.5357 - precision@0.5/amusement: 0.7114 - recall@0.5/amusement: 0.6386 - precision@0.5/anger: 0.4091 - recall@0.5/anger: 0.3879 - precision@0.5/annoyance: 0.0000e+00 - recall@0.5/annoyance: 0.0000e+00 - precision@0.5/approval: 0.0000e+00 - recall@0.5/approval: 0.0000e+00 - precision@0.5/caring: 0.0000e+00 - recall@0.5/caring: 0.0000e+00 - precision@0.5/confusion: 0.0000e+00 - recall@0.5/confusion: 0.0000e+00 - precision@0.5/curiosity: 0.5833 - recall@0.5/curiosity: 0.0443 - precision@0.5/desire: 0.4783 - recall@0.5/desire: 0.2391 - precision@0.5/disappointment: 0.0000e+00 - recall@0.5/disappointment: 0.0000e+00 - precision@0.5/disapproval: 1.0000 - recall@0.5/disapproval: 0.0061 - precision@0.5/disgust: 0.0000e+00 - recall@0.5/disgust: 0.0000e+00 - precision@0.5/embarrassment: 0.0000e+00 - recall@0.5/embarrassment: 0.0000e+00 - precision@0.5/excitement: 0.6667 - recall@0.5/excitement: 0.0377 - precision@0.5/fear: 0.0000e+00 - recall@0.5/fear: 0.0000e+00 - precision@0.5/gratitude: 0.9463 - recall@0.5/gratitude: 0.8398 - precision@0.5/grief: 0.0000e+00 - recall@0.5/grief: 0.0000e+00 - precision@0.5/joy: 0.4800 - recall@0.5/joy: 0.4500 - precision@0.5/love: 0.7239 - recall@0.5/love: 0.8082 - precision@0.5/nervousness: 0.0000e+00 - recall@0.5/nervousness: 0.0000e+00 - precision@0.5/optimism: 0.7115 - recall@0.5/optimism: 0.3854 - precision@0.5/pride: 0.0000e+00 - recall@0.5/pride: 0.0000e+00 - precision@0.5/realization: 0.0000e+00 - recall@0.5/realization: 0.0000e+00 - precision@0.5/relief: 0.0000e+00 - recall@0.5/relief: 0.0000e+00 - precision@0.5/remorse: 0.5349 - recall@0.5/remorse: 0.5750 - precision@0.5/sadness: 0.2400 - recall@0.5/sadness: 0.0667 - precision@0.5/surprise: 1.0000 - recall@0.5/surprise: 0.0125 - precision@0.5/neutral: 0.6061 - recall@0.5/neutral: 0.5007 - precision@0.5/all: 0.6185 - recall@0.5/all: 0.3586\n"
          ]
        }
      ],
      "source": [
        "model = build_model(base_layers.EVAL)\n",
        "\n",
        "# Define metrics over each category.\n",
        "metrics = []\n",
        "for i, label in enumerate(LABELS):\n",
        "  metric = tf.keras.metrics.Precision(\n",
        "      thresholds=[0.5],\n",
        "      class_id=i,\n",
        "      name='precision@0.5/{}'.format(label))\n",
        "  metrics.append(metric)\n",
        "  metric = tf.keras.metrics.Recall(\n",
        "      thresholds=[0.5],\n",
        "      class_id=i,\n",
        "      name='recall@0.5/{}'.format(label))\n",
        "  metrics.append(metric)\n",
        "\n",
        "# Define metrics over the entire task.\n",
        "metric = tf.keras.metrics.Precision(thresholds=[0.5], name='precision@0.5/all')\n",
        "metrics.append(metric)\n",
        "metric = tf.keras.metrics.Recall(thresholds=[0.5], name='recall@0.5/all')\n",
        "metrics.append(metric)\n",
        "\n",
        "model.compile(metrics=metrics)\n",
        "model.load_weights('model/model_checkpoint')\n",
        "result = model.evaluate(x=test_dataset, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Namwa3enwQBc"
      },
      "source": [
        "Print evaluation metrics for the model, as well as per emotion label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l420PosisfXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e156e1ec-309b-4ef8-f136-2442854d829c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "admiration: (precision@0.5: 0.5, recall@0.5: 0.5357142686843872)\n",
            "amusement: (precision@0.5: 0.7114093899726868, recall@0.5: 0.6385542154312134)\n",
            "anger: (precision@0.5: 0.40909090638160706, recall@0.5: 0.38793104887008667)\n",
            "annoyance: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "approval: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "caring: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "confusion: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "curiosity: (precision@0.5: 0.5833333134651184, recall@0.5: 0.04430379718542099)\n",
            "desire: (precision@0.5: 0.47826087474823, recall@0.5: 0.239130437374115)\n",
            "disappointment: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "disapproval: (precision@0.5: 1.0, recall@0.5: 0.0060606058686971664)\n",
            "disgust: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "embarrassment: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "excitement: (precision@0.5: 0.6666666865348816, recall@0.5: 0.03773584961891174)\n",
            "fear: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "gratitude: (precision@0.5: 0.9463414549827576, recall@0.5: 0.8398268222808838)\n",
            "grief: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "joy: (precision@0.5: 0.47999998927116394, recall@0.5: 0.44999998807907104)\n",
            "love: (precision@0.5: 0.7239263653755188, recall@0.5: 0.8082191944122314)\n",
            "nervousness: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "optimism: (precision@0.5: 0.7115384340286255, recall@0.5: 0.3854166567325592)\n",
            "pride: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "realization: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "relief: (precision@0.5: 0.0, recall@0.5: 0.0)\n",
            "remorse: (precision@0.5: 0.5348837375640869, recall@0.5: 0.574999988079071)\n",
            "sadness: (precision@0.5: 0.23999999463558197, recall@0.5: 0.06666667014360428)\n",
            "surprise: (precision@0.5: 1.0, recall@0.5: 0.012500000186264515)\n",
            "neutral: (precision@0.5: 0.6060861945152283, recall@0.5: 0.5006983280181885)\n",
            "all: (precision@0.5: 0.6185263395309448, recall@0.5: 0.358642578125)\n"
          ]
        }
      ],
      "source": [
        "for label in LABELS:\n",
        "  precision_key = 'precision@0.5/{}'.format(label)\n",
        "  recall_key = 'recall@0.5/{}'.format(label)\n",
        "  if precision_key in result and recall_key in result:\n",
        "    print('{}: (precision@0.5: {}, recall@0.5: {})'.format(\n",
        "        label, result[precision_key], result[recall_key]))\n",
        "    \n",
        "precision_key = 'precision@0.5/all'\n",
        "recall_key = 'recall@0.5/all'\n",
        "if precision_key in result and recall_key in result:\n",
        "  print('all: (precision@0.5: {}, recall@0.5: {})'.format(\n",
        "      result[precision_key], result[recall_key]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(0.5421106815338135*0.385009765625)/(0.5421106815338135+0.385009765625)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FWKPiFdZzc5",
        "outputId": "46d7bef3-c106-4daa-d370-1d59852a414d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2251249091525965"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "admiration: (precision@0.5: 0.7708333134651184, recall@0.5: 0.11858974397182465)  \n",
        "amusement: (precision@0.5: 0.7603305578231812, recall@0.5: 0.5508981943130493)  \n",
        "anger: (precision@0.5: 0.7058823704719543, recall@0.5: 0.104347825050354)  \n",
        "annoyance: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "approval: (precision@0.5: 1.0, recall@0.5: 0.009708737954497337)  \n",
        "caring: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "confusion: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "curiosity: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "desire: (precision@0.5: 0.4761904776096344, recall@0.5: 0.19230769574642181)  \n",
        "disappointment: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "disapproval: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "disgust: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "embarrassment: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "excitement: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "fear: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "gratitude: (precision@0.5: 0.963350772857666, recall@0.5: 0.8288288116455078)  \n",
        "grief: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "joy: (precision@0.5: 0.6399999856948853, recall@0.5: 0.20253165066242218)  \n",
        "love: (precision@0.5: 0.8571428656578064, recall@0.5: 0.5416666865348816)  \n",
        "nervousness: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "optimism: (precision@0.5: 0.7647058963775635, recall@0.5: 0.4193548262119293)  \n",
        "pride: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "realization: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "relief: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "remorse: (precision@0.5: 0.5142857432365417, recall@0.5: 0.5142857432365417)  \n",
        "sadness: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "surprise: (precision@0.5: 0.0, recall@0.5: 0.0)  \n",
        "neutral: (precision@0.5: 0.800000011920929, recall@0.5: 0.002805049065500498)  \n",
        "all: (precision@0.5: 0.8092105388641357, recall@0.5: 0.1201171875)  "
      ],
      "metadata": {
        "id": "rxRSoq_H66CK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZSWnwTMqZ5f"
      },
      "source": [
        "## Suggest Emojis using an Emotion Prediction model\n",
        "\n",
        "In this section, we apply the Emotion Prediction model trained above to suggest emojis relevant to input text.\n",
        "\n",
        "Refer to our [GoEmotions Model Card](https://github.com/google-research/google-research/blob/master/goemotions/goemotions_model_card.pdf) for additional uses of the model and considerations and limitations for using the GoEmotions data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aybpGQV1qr8I"
      },
      "source": [
        "Map each emotion label to a relevant emoji:\n",
        "* Emotions are subtle and multi-faceted. In many cases, no one emoji can truely capture the full complexity of the human experience behind each emotion. \n",
        "* For the purpose of this exercise, we will select an emoji that captures at least one facet that is conveyed by an emotion label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lgs12b90qmSQ"
      },
      "outputs": [],
      "source": [
        "EMOJI_MAP = {\n",
        "    'admiration': '👏',\n",
        "    'amusement': '😂',\n",
        "    'anger': '😡',\n",
        "    'annoyance': '😒',\n",
        "    'approval': '👍',\n",
        "    'caring': '🤗',\n",
        "    'confusion': '😕',\n",
        "    'curiosity': '🤔',\n",
        "    'desire': '😍',\n",
        "    'disappointment': '😞',\n",
        "    'disapproval': '👎',\n",
        "    'disgust': '🤮',\n",
        "    'embarrassment': '😳',\n",
        "    'excitement': '🤩',\n",
        "    'fear': '😨',\n",
        "    'gratitude': '🙏',\n",
        "    'grief': '😢',\n",
        "    'joy': '😃',\n",
        "    'love': '❤️',\n",
        "    'nervousness': '😬',\n",
        "    'optimism': '🤞',\n",
        "    'pride': '😌',\n",
        "    'realization': '💡',\n",
        "    'relief': '😅',\n",
        "    'remorse': '',\n",
        "    'sadness': '😞',\n",
        "    'surprise': '😲',\n",
        "    'neutral': '',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh_3y7OL7JG_"
      },
      "source": [
        "Select sample inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rdD6xPpn7Mjm"
      },
      "outputs": [],
      "source": [
        "PREDICT_TEXT = [\n",
        "  b'Good for you!',\n",
        "  b'Happy birthday!',\n",
        "  b'I love you.',\n",
        "  b'Who are you?',\n",
        "  b'Do not talk so loud.'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavivya6hGw0"
      },
      "source": [
        "Run inference for the selected examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tJ6iyLlLo5-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add12af3-a128-47e2-d32c-f3e40219d50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 327ms/step\n",
            "\n",
            "b'Good for you!':\n",
            "👏: 0.8067114353179932\n",
            "😃: 0.40806859731674194\n",
            "👍: 0.37184765934944153\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "b'Happy birthday!':\n",
            "😃: 0.9798732995986938\n",
            "🤩: 0.5317233800888062\n",
            "😳: 0.3652009665966034\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "b'I love you.':\n",
            "❤️: 0.9999984502792358\n",
            "😡: 0.3247499167919159\n",
            "🙏: 0.3211614787578583\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "b'Who are you?':\n",
            "🤔: 0.5164777040481567\n",
            "neutral: 0.4811791479587555\n",
            "😡: 0.3884563744068146\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "b'Do not talk so loud.':\n",
            "neutral: 0.42998552322387695\n",
            "👎: 0.4268779754638672\n",
            "😕: 0.36860185861587524\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "model = build_model(base_layers.PREDICT)\n",
        "model.load_weights('model/model_checkpoint')\n",
        "\n",
        "for text in PREDICT_TEXT:\n",
        "  results = model.predict(x=[text])\n",
        "  print('')\n",
        "  print('{}:'.format(text))\n",
        "  labels = np.flip(np.argsort(results[0]))\n",
        "  for x in range(3):\n",
        "    label = LABELS[labels[x]]\n",
        "    label = EMOJI_MAP[label] if EMOJI_MAP[label] else label\n",
        "    print('{}: {}'.format(label, results[0][labels[x]]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVH7Pbj-AAST"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}